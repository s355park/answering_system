Continuous Random Variables 5.1 Introduction In Chapter 4 we considered discrete random variables, that is, random variables whose set of possible values is either ﬁnite or countably inﬁnite. However, there also exist random variables whose set of possible values is uncountable. Two examples would be the time that a train arrives at a speciﬁed stop and the lifetime of a transistor. Deﬁnition : We say that X is a continuous random variable if there exists a nonnegative function f , deﬁned for all real x ∈ ( −∞ , ∞ ) , having the property that for any set B of real numbers P { X ∈ B } = Z B f ( x ) dx The function is called the probability density function (pdf) of the random variable X . Since X must assume some value, f must satisfy 1 = P { X ∈ ( −∞ , ∞ ) } = Z ∞ −∞ f ( x ) dx Relation of CDF and pdf : P { X < a } = P { X ≤ a } = F ( a ) = Z a −∞ f ( x ) dx ©A. K. Khandani, E&CE307—Fall 2024 73 5.2 Expectation and Variance of Continuous Random Variables Expected Value : The expected value of the discrete random variable X , which we denote by E ( X ) , is given by E ( X ) = Z ∞ −∞ xf ( x ) dx Expectation of a Function of a Continuous Random Variable : If X is a continuous random variable with probability density function f ( x ) , then for any real-valued function g , E ( g ( X )) = Z ∞ −∞ g ( x ) f ( x ) dx Lemma : For a nonnegative random variable Y , E ( Y ) = Z ∞ 0 P { Y > y } dy Corollary : If a and b are constants, then E [ aX + b ] = aE [ X ] + b ©A. K. Khandani, E&CE307—Fall 2024 74 5.3 The Uniform Random Variable Uniform Random Variable : We sat that X is a uniform random variable on the interval ( α, β ) if its probability density function is given by f ( x ) =    1 β − α if α < x < β 0 otherwise Since F ( a ) = Z a −∞ f ( x ) dx , F ( a ) =        0 a ≤ α a − α β − α if α < a < β 1 a ≥ α For a uniformly distributed random variable X over ( α, β ) E [ X ] =  α + β 2 and Var ( X ) = ( β − α ) 2 12 ©A. K. Khandani, E&CE307—Fall 2024 75 5.4 Normal Random Variables Normal Random Variable : We say that X is a normal random variable , or simply that X is normally distributed , with parameters µ and σ 2  if the density of X is given by f ( x ) = 1 √ 2 πσ e − ( x − µ ) 2 / 2 σ 2 For a normally distributed random variable X with parameters µ and σ 2 , E [ X ] = µ and Var ( X ) = σ 2 If X has the pdf N ( µ, σ 2 ) , then Y = aX + b has the pdf f Y ( y ) = 1 √ 2 πσ  exp ( − 1 2 σ 2  y − b a  − µ  2 ) ·  1 | a | , −∞ < y < ∞ = 1 √ 2 π | a | σ  · exp " − ( y − aµ − b ) 2 2 a 2 σ 2 # , −∞ < y < ∞ which is the pdf of N ( aµ + b, a 2 σ 2 ) . Note that a linear transformation of a normal random variable results in a normal random variable. ©A. K. Khandani, E&CE307—Fall 2024 76 Standard Normal Random Variable : Standard normal random variable is a normal random variable with parameters (0 , 1) . That is, f Z ( z ) = 1 √ 2 π e − z 2 / 2 It is traditional to denote the cumulative distribution function of a standard normal random variable by Φ( x ) . That is, Φ( x ) = 1 √ 2 π Z x −∞ e − y 2 / 2 dy For any normal random variable X with parameters ( µ, σ 2 ) , Z =  X − µ σ is a normal random variable and its cumulative distribution function can be written as F X ( a ) = P { X ≤ a } = P  X − µ σ ≤ a − µ σ  = Φ  a − µ σ  5.4.1 The Normal Approximation to the Binomial Distribution The DeMoivre-Laplace Limit Theorem : If S n denotes the number of successes that occur when n indepen- dent trials, each resulting in a success with probability p , are performed then, for any a < b , P ( a ≤ S n − np p np (1 − p )  ≤ b ) → Φ( b ) − Φ( a ) ©A. K. Khandani, E&CE307—Fall 2024 77 5.5 Exponential Random Variable Exponential Random Variable : A continuous random variable whose probability density function is given, for some λ > 0 , by f ( x ) =  λe − λx if x ≥ 0 0 if x < 0 is said to be an exponential random variable (or, more simply, is said to be exponentially distributed) with parameter λ . The cumulative distribution F ( a ) of an exponential random variable is given by F ( a ) = P { X ≤ a } = Z a 0 λe − λx dx = − e − λx  a 0 = 1 − e − λa a ≥ 0 For an exponential random variable X with parameter λ , E [ X ] = 1 λ and Var( X ) = 1 λ 2 ©A. K. Khandani, E&CE307—Fall 2024 78 Memoryless Random Variable : We say that a nonnegative random variable X is memoryless if P { X > s + t | X > t } = P { X > s } for all s, t ≥ 0 Since the above equation is satisﬁed when X is exponentially distributed, it follows that exponentially distributed random variables are memoryless. 5.5.1 Hazard Rate Functions Hazard Rate Function : Consider a positive continuous random variable X that we interpret as being the lifetime of some item, having distribution function F and density f . The hazard rate (sometimes called the failure rate function λ ( t ) of F is deﬁned by λ ( t ) =  f ( t ) F ( t ) F ( t ) = 1 − F To interpret λ ( t ) , suppose that the item has survived for a time t and we desire the probability that it will not survive for an additional time dt . That is, consider P { X ∈ ( t, t + dt ) | X > t } . Now P { X ∈ ( t, t + dt ) | X > t } = P { X ∈ ( t, t + dt ) , X > t } P { X > t } = P { X ∈ ( t, t + dt ) } P { X > t } ≈ f ( t ) F ( t ) dt Thus, λ ( t ) represents the conditional probability intensity that a t -unit-old item will fail. For an exponentially distributed random variable, the hazard rate function is constant. ©A. K. Khandani, E&CE307—Fall 2024 79 5.6 Other Continuous Distributions 5.6.1 The Gamma Distribution The Gamma Distribution : A continuous random variable is said to have a gamma distribution with parameters ( α, λ ) , λ > 0 , and α > 0 if its density function is given by f ( x ) =    λe − λx ( λx ) α − 1 Γ( α ) if x ≥ 0 0 if x < 0 where Γ( α ) , called the gamma function, is deﬁned as Γ( α ) = Z ∞ 0 e − y y α − 1 dy The integration by parts of Γ( α ) yields that Γ( α ) = ( α − 1)Γ( α − 1) For integer values of n Γ( n ) = ( n − 1)! ©A. K. Khandani, E&CE307—Fall 2024 80 When α is a positive integer, say α = n , the gamma distribution with parameters ( α, γ ) often arises as the distribution of the amount of time one has to wait until a total of n events has occurred, when the conditions told for Poisson distribution are valid. Let T n denote the time at which the n th event occurs, and note T n is less then or equal to t if and only if the number of events that have occurred by time t is at least n . That is, when N ( t ) equal to the number of events in [0 , t ] , P { T n ≤ t } = P { N ( t ) ≥ n } = ∞ X j = n P { N ( t ) = j } = ∞ X j = n e − λt ( λt ) j j ! where the ﬁnal identity follows because the number of events in [0 , t ] has a Poisson distribution with parameter λt . Diﬀerentiation of the above yields that the density function of T n is as follows: f ( t ) = ∞ X j = n e − λt j ( λt ) j − 1 λ j ! − ∞ X j = n λe − λt ( λt ) j j ! = ∞ X j = n λe − λt ( λt ) j − 1 ( j − 1)! − ∞ X j = n λe − λt ( λt ) j j ! = λe − λt ( λt ) n − 1 ( n − 1)! Note that when n = 1 , this distribution reduces to the exponential. For a gamma distributed random variable we have, E [ X ] =  α λ and Var( X ) =  α λ 2 ©A. K. Khandani, E&CE307—Fall 2024 81 5.6.2 The Weibull Distribution The Weibull Distribution : The Weibull distribution function has the form F ( x ) =      0 x ≤ ν 1 − exp ( −  x − ν α  β ) x > ν Diﬀerentiation yields the density is f ( x ) =      0 x ≤ ν β α  x − ν α  β − 1 exp ( −  x − ν α  β ) x > ν 5.6.3 The Cauchy Distribution The Cauchy Distribution : The Cauchy density function has the form f ( x ) = 1 π 1 1 + ( x − θ ) 2 ©A. K. Khandani, E&CE307—Fall 2024 82 5.6.4 The Beta Distribution The Beta Distribution : The beta density function has the form f ( x ) =    1 B ( a, b ) x a − 1 (1 − x ) b − 1 0 < x < 1 0 otherwise where B ( a, b ) = Z 1 0 x a − 1 ( a − x ) b − 1 dx The following relationship exists between B ( a, b ) and gamma function: B ( a, b ) = Γ( a )Γ( b ) Γ( a + b ) For a beta distributed random variable, E [ X ] = a a + b and Var( X ) = ab ( a + b ) 2 ( a + b + 1) 5.7 The Distribution of a Function of a Random Variable Theorem : Let X be a continuous random variable having probability density function f X . Suppose that g ( x ) is a strictly monotone (increasing or decreasing), diﬀerentiable (and thus continuous) function of x . Then the random variable Y deﬁned Y = g ( X ) has a probability density function given by f Y ( y ) =    f X [ g − 1 ( y )]  d dy g − 1 ( y )  if y = g ( x ) for some x 0 if y ̸ = g ( x ) for all x ©A. K. Khandani, E&CE307—Fall 2024 83 5.8 Some Solved Problems 1. Consider the probability density f X ( x ) = a e − b | x | , where X is a random variable whose allowable values range from x = −∞ to x = + ∞ . Find ( a ) the cumulative distribution function F X ( x ) , ( b ) the relationship between a and b , and ( c ) the probability that the outcome X lies between 1 and 2. Solution: ( a ) The cumulative distribution function is F ( x ) = P ( X ≤ x ) = Z x −∞ f ( x ) dx = Z x −∞ a e − b | x |  dx =      a b e bx x ≤ 0 1 2 + a b  (1 − e − bx ) x ≥ 0 ( b ) In order that f ( x ) be a probability density, it is necessary that Z + ∞ −∞ f ( x ) dx = Z + ∞ −∞ a e − b | x | dx = 2 a b = 1 so that  a b  = 1 2  . ( c ) The probability that X lies in the range between 1 and 2 is P (1 ≤ X ≤ 2) =  b 2 Z 2 1 e − b | x |  dx = 1 2 ( e − b − e − 2 b ) 2. A certain retailer for a petroleum product sells a random amount, X , each day. Suppose that X , measured in hundreds of gallons, has the probability density function f X ( x ) =  (3 / 8) x 2 0 ≤ x ≤ 2 0 elsewhere. The retailer’s proﬁt turns out to be $5 for each 100 gallons sold (5 cents per gallon) if X ≤ 1 and $8 per 100 gallons if X > 1 . Find the retailer’s expected proﬁt for any given day. Solution: Let g ( X ) denote the retailer’s daily proﬁt. Then, g ( X ) =  5 X, 0 ≤ x ≤ 1 8 X, 1 < x ≤ 2 We want to ﬁnd expected proﬁt, and E [ g ( X )] = Z ∞ −∞ g ( x ) f ( x ) dx = Z 1 0 5 x  3 8  x 2  dx + Z 2 1 8 x  3 8  x 2  dx = 15 (8)(4) [ x 4 ] 1 0  + 24 (8)(4) [ x 4 ] 2 1 = 15 32 (1) + 24 32 (15) = (15)(25) 32 = 11 . 72 3. Let X have the probability density function given by f X ( x ) =  2 x 0 < x < 1 0 elsewhere. ©A. K. Khandani, E&CE307—Fall 2024 84 (a) Find the density function of U = 3 X − 1 . (b) Find the density function of U = − 4 X + 3 . Solution: We know that for a given pdf, say f X ( x ) , the probability that X is in a neighborhood of ∆ x around x is given by f X ( x )∆ x . In this problem, the value of U is uniquely determined by the value of X . Then, the probability that U is in a neighborhood of ∆ u around u , i.e., f U ( u )∆ u , is equal to the probability that X is in a neighborhood of ∆ x around x = h − 1 ( u ) where h ( x ) = 3 x − 1 . This means that f U ( u )∆ u = f X [ h − 1 ( u )]∆ x = ⇒ f U ( u ) = f X [ h − 1 ( u )] ∆ x ∆ u . Here, we have, x = h − 1 ( u ) =  u + 1 3 and ∆ x ∆ u  = dx du  = 1 3 Thus, f U ( u ) = f X [ h − 1 ( u )] dx du  = 2 xdx du = 2 ·  u + 1 3 ·  1 3 = 2( u + 1) 9 − 1 < u < 2 = 0 elsewhere The range of u (i.e., the range over which f U ( u ) is positive) is simply the interval 0 < x < 1 transformed to the u -axis by the function u = 3 x − 1 . This results in u ∈ [ − 1 , 2] . For u = h ( x ) = − 4 x + 3 , we have, x = h − 1 ( u ) = 3 − u 4 and dx du  = − 1 4 As the function h ( x ) is decreasing in x , we have ∆ x/ ∆ u = − dx/du (note that ∆ x and ∆ u are always positive but dx and du may be positive or negative) and we can write, f U ( u ) = f X [ h − 1 ( u )]  dx du  = 2 x  dx du  = 2 ·  3 − u 4 ·  1 4 = 3 − u 8 − 1 < u < 3 = 0 elsewhere The range of u is equal to, u ∈ [ − 1 , 3] . 4. Consider a random variable X with the following pdf: f X ( x ) = 1 − a | x | , | x | ≤ 1 /a ©A. K. Khandani, E&CE307—Fall 2024 85 (a) Find the constant a and compute the mean and the standard deviation of X . (b) The random variable X is applied to a “full-wave” rectiﬁer whose output-input gain characteristic is y = b | x | . Determine the mean and standard deviation of the output random variable. (c) The random variable X is applied to a “half-wave” rectiﬁer whose output-input gain characteristic is y = b | x | , x ≥ 0 and y = 0 , x < 0 . Determine the mean and standard deviation of the output random variable. Solution: The pdf of X is shown in the following ﬁgure. 1 − 1 /a 1 /a Figure 7: Pdf related to above Problem. We should have, Z ∞ −∞ f X ( x ) dx = Z 1 /a − 1 /a f X ( x ) = 1 This results in a = 1 . We also have: E ( X ) = 0 and, σ X = q E ( X 2 ) = q 1 / 6 In parts 2 and 3, we want to compute the average value of a function of a random variable. Given a random variable X , the general formula for the average value of the function H ( X ) is, E [ H ( X )] = Z ∞ −∞ H ( X ) f X ( x ) dx For the case of full wave rectiﬁer, the function is equal to, H ( X ) = b | X | . This results in, E ( Y ) = E ( b | X | ) = b [ Z 0 − 1 ( − x ) f X ( x ) dx + Z 1 0 xf X ( x ) dx ] = 2 b Z 1 0 x (1 − x ) dx =  b 3 and, similarly, E ( Y  2 ) = 2 b 2 Z 1 0 x 2 (1 − x ) dx =  b 2 6 This results in σ Y = p [ E ( Y  2 )] − [ E ( Y )] 2  = p b 2 / 18 . For the case of half wave rectiﬁer, we note that the output is in part continuous and in part discrete (note that all the negative value of X are mapped to zero). This means that the output of the half-rectiﬁer is with probability 1 / 2 equal to zero, while for values greater than zero, it obeys the pdf of X . This results in, E ( Y ) = (0 × 1 / 2) + Z 1 0 bx (1 − x ) dx =  b 6 ©A. K. Khandani, E&CE307—Fall 2024 86 and E ( Y  2 ) = (0 2  × 1 / 2) + Z 1 0 b 2 x 2 (1 − x ) dx =  b 2 12 This results in σ Y = p [ E ( Y  2 )] − [ E ( Y )] 2  = p b 2 / 18 . 5. The random variable X of the life length of certain kind of battery (in hundreds of hours) is equal to: f ( x ) =  1 2 e − x/ 2 x > 0 0 otherwise (i) Find the probability that the life of a given battery is less than 200 or greater than 400 hours. (ii) Find the probability that a battery of this type lasts for 300 hours if we know that it has already been in use for 200 hours. Solution: (i) Let A denote the event that X is less than 2 and B the event that X is greater than 4. Then, because A and B are mutually exclusive, P ( A ∪ B ) = P ( A ) + P ( B ) = Z 2 0 1 2 e − x/ 2 dx + Z ∞ 4 1 2 e − x/ 2 dx = (1 − e − 1 ) + e − 2 = 1 − 0 . 368 + 0 . 135 = 0 . 767 (ii) We are interested in P ( X > 3 | X > 2) and, by the deﬁnition of conditional probability, P ( X > 3 | X > 2) =  P ( X > 3) P ( X > 2) because the intersection of the events ( X > 3) and ( X > 2) is the event ( X > 3) . Now P ( X > 3) P ( X > 2) = Z ∞ 3 1 2 e − x/ 2 dx Z ∞ 2 1 2 e − x/ 2 dx =  e − 3 / 2 e − 1 = e − 1 / 2  = 0 . 606 6. The failure of a circuit board interrupts work by a computer system until a new board is delivered. Delivery time X is uniformly distributed over the interval 1 to 5 days. The cost C of this failure and interruption consists of a ﬁxed cost c 0 for the new part and a cost that increases proportional to X 2 , i.e, C = c 0 + c 1 X 2 (a) Find the probability that the delivery time takes 2 or more days. (b) Find the expected cost of a single failure, in terms of c 0 and c 1 . Solution: (a) The delivery time X is distributed uniformly from 1 to 5 days, which gives f ( x ) =    1 4 1 ≤ x ≤ 5 0 elsewhere Thus, P ( X ≥ 2) = Z 5 2  1 4  dx = 1 4 (5 − 2) = 3 4 ©A. K. Khandani, E&CE307—Fall 2024 87 (b) We know that E ( C ) = c 0 + c 1 E ( X 2 ) so it remains to ﬁnd E ( X 2 ) . This could be found directly from the deﬁnition or by using the variance and the fact that E ( X 2 ) = V ( X ) + µ 2 Using the latter approach, E ( X 2 ) = ( b − a ) 2 12 +  a + b 2  2 = (5 − 1) 2 12 +  1 + 5 2  2 = 31 3 Thus, E ( C ) = c 0 + c 1  31 3  7. Let X denote the life time (in hundreds of hours) of a certain type of electronic component. These components frequently fail immediately upon insertion into the system. It has been observed that the probability of immediate failure is 1/4. If a component does not fail immediately, the life-length distribution has the exponential density: f ( x ) =  e − x x > 0 0 elsewhere Find the distribution function for X and evaluate P ( X > 10) . Solution: There is only one discrete point, X = 0 , and this point has probability 1/4. It follows that X is a mixture of two random variables, X 1 and X 2 , where X 1 has a probability of one at the point zero and X 2 has the given exponential density. That is, F 1 ( x ) =  0 if x < 0 1 if x ≥ 0 and F 2 ( x ) = Z x 0 e − y  dy = 1 − e − x x > 0 Now, F ( x ) =  1 4  F 1 ( x ) +  3 4  F 2 ( x ) Hence, P ( X > 10) = 1 − P ( X ≤ 10) = 1 − F (10) = 1 −  1 4 +  3 4  (1 − e − 10 )  =  3 4  [1 − (1 − e − 10 )] =  3 4  e − 10 ©A. K. Khandani, E&CE307—Fall 2024 88 8. Suppose X has density function f ( x ) for − 1 ≤ x ≤ 1 , 0 otherwise. Find the density function of (a) Y = | X | , (b) Z = X 2 . Solution: (a) For y > 0 , P ( Y ≤ y ) = P ( − y ≤ X ≤ y ) = F ( y ) − F ( − y ) . Diﬀerentiating the cdf, we conclude that the pdf of Y is f ( y ) + f ( − y ) for 0 < y < 1 and 0 elsewhere. You may also try to use the following relationship: f Y ( y ) = X x i f X ( x i )  dy dx  (b) For z > 0 , P ( Z ≤ z ) = P ( − √ z ≤ X ≤ √ z ) = F ( √ z ) − F ( − √ z ) . Hence the pdf of Z is [ f ( √ z ) + f ( − √ z )] · ( 1 2 z − 1 / 2 ) , for z > 0 and 0 otherwise. 9. Suppose X is uniform on (0,1). Find the density function of Y = X n . Solution: Suppose X has density f X and P ( a < X < b ) = 1 . Let Y = r ( X ) . Suppose r : ( a, b ) → ( α, β ) is continuous and strictly increasing, and let s : ( α, β ) → ( a, b ) be the inverse of r . Then, we know that Y has density f Y ( y ) = f X [ s ( y )] s ′ ( y ) for y ∈ ( α, β ) Therefore, since X has density function f X ( x ) = 1 for 0 < x < 1 , and r ( x ) = x n  has inverse s ( x ) = x 1 /n , the theorem gives the density function f X ( y 1 n ) ·  1 n y 1 n  − 1  = 1 n y 1 n  − 1  for 0 < y < 1 . 10. Suppose X is uniform on (0 , π/ 2) and Y = sin X . Find the density function of Y . The answer is called the arcsine law because the distribution function contains the arcsine function. Solution: The density function of X is f X ( x ) = 2 /π for 0 < x < π/ 2 and r ( x ) = sin x has the inverse s ( x ) = sin − 1  x . Using the same result as in the previous problem, we obtain the density function f X [ s ( y )] · s ′ ( y ) = 2 π  · 1 p 1 − y 2 for 0 < y < 1 . 11. Suppose X has density function 3 x − 4  for x ≥ 1 . (a) Find a function g so that g ( X ) is uniform on (0,1). (b) Find a function h so that if U is uniform on (0,1), h ( U ) has density function 3 x − 4  for x ≥ 1 . Solution: Suppose X has a continuous distribution. Then Y = F X ( X ) is uniform on (0,1). (a) P ( X ≤ x ) = Z x 1 3 y − 4  dy = 1 − x − 3  for x > 1 and 0 elsewhere. The above statement tells that Y = g ( X ) = 1 − X − 3  is uniform on (0,1). Suppose U has a uniform distribution on (0,1). Then Y = F  − 1 ( U ) has distribution function F . (b) F ( x ) has inverse F  − 1 ( x ) = (1 − x ) − 1 3 . The above statement says that F  − 1 ( U ) = (1 − U ) − 1 3 has the given density function. 12. A Gaussian distributed random variable X with zero mean and the unit variance is applied to a “full-wave” rectiﬁer whose output-input gain characteristic is y = | x | /a, a > 0 . Determine the pdf of the output random variable Y. The mapping is one-to-one for x < 0 and one-to-one for x > 0 . In both cases, y > 0 . Using the equation f Y ( y ) =  f X ( x ) | dy/dx | ©A. K. Khandani, E&CE307—Fall 2024 89 we have for x > 0 f Y ( y ) = a  1 √ 2 π e − x 2 / 2  x = ay = a √ 2 π e − a 2 y 2 / 2 y > 0 and for x < 0 f Y ( y ) = a  1 √ 2 π e − x 2 / 2  x = − ay = a √ 2 π e − a 2 y 2 / 2 y > 0 Adding these two results, we obtain, f Y ( y ) = a r 2 π e − a 2 y 2 / 2 u ( y ) . We could equivalently use the following relationship: f Y ( y ) = X k f X ( x k ) | dg/dx k |  x k = g − 1 ( y ) where g ( x ) = | x | /a . 13. The random variable X of the previous problem is applied to the half-wave rectiﬁer whose output-input characteristic is y = ( x/a ) u ( x ) . Determine the pdf of the output. Solution: For x > 0 , it can easily be shown that f y ( y ) = a √ 2 π e − a 2 y 2 / 2 , y > 0 For x < 0 , however all points of the input are mapped into zero in the output. To conserve probability we must add a contribution of R 0 −∞ f X ( x ) dx = 1 / 2 at the point y = 0 so that f y ( y ) = a √ 2 π e − a 2 y 2 / 2 u ( y ) +  1 2  δ ( y ) 14. Suppose X has density x − 2  for x ≥ 1 and Y = X − 2 . Find the pdf of Y . Solution: Noting P ( Y ≤ x ) = P ( X ≥ x − 1 2 ) = 1 − F ( x − 1 2 ) for x ≤ 1 leads to the density function of Y by diﬀerentiating: d dx P ( Y ≤ x ) = F ′ ( x − 1 2 )( 1 2 x − 3 / 2 ) = 1 2 x − 1 / 2 , forx ≤ 1 15. The actual weight of a bag of sugar is assumed to be a normal random variable with mean 202 grams and standard deviation of 3 grams. If a bag weighs less than 199 grams or more than 205 grams it is rejected. (i) What is the probability that a bag will be rejected? (ii) Given that a bag was rejected, what is the probability it weighs less than 195 grams? (iii) If the standard deviation of the ﬁlling process is changed to σ , but the mean remains at 202 grams, what is the largest value that σ can have so that the probability a bag is rejected is less than .01? Give numerical answers. Solution: (i) P ( bag rejected ) = 1 − P (199 < X < 205) = 1 − P ( 199 − 202 3 < X − 202 3 <  205 − 202 3 ) = 1 − (Φ(1) − Φ( − 1)) = 0 . 84134 − 0 . 15866 = 0 . 31732 . (ii) Let A = bag rejected, B = { X < 195 } , then P ( B | A ) = P ( AB ) /P ( A ) = P ( X < 195) /P ( A ) = Φ( 195 − 202 3 ) / 0 . 31732 = Φ( − 7 / 3) / 0 . 31732 = 0 . 00982 / 0 . 31732 . = 0 . 0309 . ©A. K. Khandani, E&CE307—Fall 2024 90 (iii) P ( bag rejected ) = 1 − Φ(3 /σ ) − Φ( − 3 /σ ) = 2(1 − Φ(3 /σ ) = . 01 or Φ(3 /σ ) = . 995 and 3 /σ = 2 . 575 and σ = 1 . 165 . 16. The error in a linear measurement, is assumed to be a normal random variable with mean 0 and variance σ 2 , in mm 2 . (i) What is the largest value of σ allowable if P ( | X | < 2) is to be at least 0.90? (ii) If σ = 2 evaluate P ( X > 4 | | X | < 5) . Solution: (i) P ( | X | < 2) = Φ(2 /σ ) − Φ( − 2 /σ ) = 2Φ(2 /σ ) − = 0 . 9 or Φ(2 /σ ) = 0 . 95 and 2 /σ = 1 . 65 and σ = 1 . 212 . (ii) P ( X > 4 || X | < 5) = P ( X > 4 and | X | < 5) /P ( | X | < 5) = Φ(5 / 2) − Φ(4 / 2) Φ(5 / 2) − Φ( − 5 / 2) = 0 . 0167 . 17. The projection of a point chosen at random on the circumference of a circle of radius a onto a ﬁxed diameter, has the cdf: F X ( x ) =      1 x ≥ a 1 2 + 1 π arcsin x a − a ≤ x ≤ a 0 otherwise (i) Determine the probability that X will be on the interval ( − a/ 2 , a/ 2) (ii) Find the probability density function of X (iii) Find the mode and the median of the distribution. Solution: (i) P ( − a 2  < X < a 2 ) = F X ( a 2 ) − F X ( − a 2 ) = 2 π arcsin (1 2 ) = 1 3 . The density function is given by f X ( x )  d dx F X ( x ) = d dx (1 2 + 1 π arcsin ( x a )) = 1 π ( a 2  − x 2 ) 1 / 2 , − a ≤ x ≤ a and zero otherwise. The mode of the distribution is the point at which the pdf achieves its maximum value. This distribution has no mode. The median is the point at which F X ( x ) = 1 / 2 , which is x = 0 . 18. The signal strength in volts at the input to an antenna, is a random variable with cdf F ( x ) = 1 − e − x 2 /a  , x ≥ 0 , a > 0 . (i) Find the probability density function, mean and variance of X . (ii) If ten independent samples of the signal strength are taken, what is the probability that exactly 7 of them will be greater than 2 volts? ©A. K. Khandani, E&CE307—Fall 2024 91 Solution: (i) The probability density function is: f X ( x ) =  d dx F X ( x ) = 2 x a e − x 2 /a , x ≥ 0 E ( X ) = 2 a Z ∞ 0 x 2 e − x 2 /a dx = √ aπ 2 E ( X 2 ) = 2 a Z ∞ 0 x 3 e − x 2 /a dx = a E ( X ) = a (1 − π 4 ) (ii) The probability that one sample is greater than 2 is p = exp( − 4 /a ) = 1 − F X (2) and so: P ( 7 out of 10 greater than 2 ) =  10 7 ! p 7 (1 − p ) 3  . 19. The random variable X is normal with mean 81 and variance 16 while Y is normal with mean 85 and variance 4. Which random variable is more likely to be less than 88? Solution: P ( X ≤ 88) = P ( X − 81 4 ≤ 7 4 ) = Φ(7 4 ) P ( Y ≤ 88) = P ( Y − 85 2 ≤ 3 2 ) = Φ(3 2 ) and hence X is more likely to be less than 88 . 20. The lifetime of an electronic component is a random variable which has an exponential pdf. If 50% of the components fail before 2,000 hours, what is the average lifetime of the component? Solution: The pdf is of the form α exp( − αx ) and P ( X ≤ 2000) = 1 − exp( − 2 , 000 α ) = 0 . 5 Thus α = − ln(0 . 5) / 2 , 000 and the average lifetime of the component is 1 /α = 2 , 000 / ln(2) . 21. The probability density function of a random variable X is f X ( x ) = ax 2 e − kx , k > 0 , 0 ≤ x < ∞ . Find: (i) the coeﬃcient a in terms of k . (ii) the cdf of X . (iii) The probability that 0 ≤ X ≤ 1 /k . Solution: (i) From the formula for the gamma function it is easily shown that Z ∞ 0 ax 2 e − kx dx = 2 a k 3 . and a = k 3 / 2 . (ii) The cdf is F X ( x ) = Z x 0 k 3 2  y 2 e − ky dy = 1 − k 2 x 2 + 2 k + 2 2 e − kx  , x ≥ 0 . (iii) P (0 ≤ X ≤ 1 k ) = F X (1 k ) = 1 − 5 2 e − 1 . ©A. K. Khandani, E&CE307—Fall 2024 92 22. A machine shop has a large number of drilling machines. The number of breakdowns follows a Poisson probability law with a mean rate of 3 per hour. One service station operates to repair the machines, with a service time that has an exponential distribution with a mean of .25 hours. (i) What is the probability that, at any given instant, the service station is idle? (ii) What is the expected queue length? (iii) What is the smallest service rate allowable to achieve an expected queue length less than 2? (iv) What is the smallest number of servers required to achieve an average queue length of less than 1 if each server has an exponential distribution with a mean of .25 hours? Solution: (i) For the M/M/1 queue, ρ = λ/µ = 3 / 4 and P 0 = (1 − ρ ) = 1 / 4 and the probability the machine will have to wait for service is 1 − P 0 = 3 / 4 . (ii) E ( N q ) = ρ 2 1 − ρ  = (3 / 4) 2 1 − (3 / 4) = 9 4 . (iii) To reduce E ( N q ) to 2 we require ρ 2 / (1 − ρ ) = 2 or ρ 2  = 2(1 − ρ ) or ρ = − 1 ± √ 3 Thus ρ = 3 /µ = √ 3 − 1 or µ is at least 3 / ( √ 3 − 1) . (iv) In an M/M/2 queue E ( N q ) = P 0  ρ 3 (2 − ρ ) 2 ! = P o  3 4  3  4 5  2 = P o 27 100 and thus P 0 =  1 + ρ +  ρ 2 5 / 4 ! − 1 = 5 11 and thus E ( N q ) = 5 11 27 100  < 1 and two servers will suﬃce. 23. (a) In an M/M/1 (single server) queue, customers arrive at the rate of λ = 15 per hour. What is the minimum server rate to ensure that: (i) the server is idle at least 10% of the time? (ii) the expected value of the queue length is not to exceed 10 (iii) the probability there at least 20 people in the queue is at most 0.50 (b) If n arrivals occurred in the time interval (0 , t ) , ﬁnd the probability density function, g ( s ) , of the time to the ﬁrst arrival. Solution: a) (i) For P 0 ≥ 0 . 10 ⇒ 1 − ρ ≤ 0 . 10 ⇒ λ/µ ≤ 0 . 90 and thus µ ≥ λ/ 0 . 90 = 16 . 67 . (ii) E ( N q ) ≤ ρ 2 / (1 − ρ ) ⇒ 10 ≤ ρ 2 / (1 − ρ ) and the solution to this quadratic equation is ρ = − 5 ± √ 35 or ρ ≥− 5 + √ 35 and µ ≤ 15 / ( − 5 + √ 35) = 16 . 375 . ©A. K. Khandani, E&CE307—Fall 2024 93 (iii) For there to be at least 20 in the queue there are at least 21 in the system. P ( n ≥ 21) = ∞ X n =21 (1 − ρ ) ρ n  = ρ 21  ≤ . 5 ⇒ ρ ≤ exp( ln (0 . 5) / 21) ⇒ µ ≥ 15 / exp( ln (0 . 5) / 21) b) Let the required probability density function be g ( s ) . Then: g ( s ) ds = λds h ( λ ( t − s )) n − 1 e − λ ( t − s ) / ( n − 1)! i e − λs / h ( λt ) n e − λt /n ! i = n ( t − s ) n − 1 ds/t n = n (1 − s/t ) n − 1 ds/t ⇒ g ( s ) = n (1 − s/t ) n − 1 /t , 0 ≤ s ≤ t ©A. K. Khandani, E&CE307—Fall 2024 94